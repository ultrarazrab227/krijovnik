                      Крыжовник
На протяжении всего финала НТО 2023 наша команда долго и упорно трудилась над написанием программного кода для автономного полёта коптера, обнаружения очагов возгорания и пострадавших.
Краткое описание решаемой задачи:
1.	Взлет:
1.1	Совершить автономный взлет с зоны «Н».
1.2	Установить значение высоты дрона не более 1.5 метров, возможно изменение в течение миссии, но только в меньшую сторону (не поднимать дрон выше стены).
2.	Автоматизированный поиск очагов возгорания в помещении при помощи автономного квадрокоптера:
2.1	Прилететь к точке начала мониторинга (постоянна, известна).
2.2	Начать движение по любой траектории, позволяющей обнаружить возгорания, находящиеся внутри помещения (светло-серая зона на Рис. 1).
2.2.1	В случае выхода проекции квадрокоптера за пределы помещения на 5 секунд и более, считается, что дрон окончил мониторинг и дальнейших действий не планируется. Дальнейшие баллы не начисляются.
2.3	Определить длину каждой стены, согласно нумерации ниже:  2.3.1 Отобразить каждую стену, привязанную к системе координат, в системе визуализации любым возможным методом (marker array, point cloud, и т.д.; важно чтобы была возможность различить стены на экране)
2.4Обнаружить все возгорания (при их наличии). 
2.4.1	Отобразить возгорания, привязанные к системе координат в системе визуализации (Rviz или аналоге, используя marker array), форма и размер значение не имеет, цвет - оранжевый.
2.4.2	Сделать запрос на сервер с координатами возгорания. Формат запроса указан в OpenAPI документации.
2.4.3	В зависимости от полученного результата определяем класс пожара (данная функция необходима для выполнения дальнейшего задания).
2.4.4	Вывести в терминал сообщение о координатах обнаруженных возгораний относительно aruco_map типе пожара и хранящемся в нем веществе. Формат: fire: <x> <y> <material> <class>В пункте <material> указывается конкретный тип.
2.4.5	2.4.5 После обнаружения возгорания и определения его типа, необходимо выполнить сброс необходимой капсулы. Класс А - цилиндр, класс В - куб.
2.5	Обнаружить пострадавших в пожаре рабочих. На всех рабочих были надеты каски синего цвета. 
2.5.1	Вывести в терминал координаты обнаруженных пострадавших Формат: injured: <x> <y>
2.5.2	Отобразить местонахождение пострадавших с привязкой к системе координат в системе визуализации (Rviz или аналоге, используя marker array), форма и размер значение не имеет, цвет -синий.
2.5.3	 Определить ближайший очага возгорания.
2.6	Продолжить мониторинг, в случае обнаружения иных возгораний повторить пункт 2.3-2.5;
3.	По окончанию мониторинга помещения, вернуться в зону «Н»;
4.	Совершить автономную посадку в пределах зоны «H».

Наш код решения данной задачи на языке программирования Python с пояснениями:




import rospy
	import math
	import cv2 as cv
	import numpy as np
	from cv_bridge import CvBridge
	from sensor_msgs.msg import Image
	from clover.srv import SetLEDEffect
	from clover import srv
	from std_srvs.srv import Trigger
	#импорт библиотек
	

	

	rospy.init_node('computer_vision_sample')
	bridge = CvBridge()
	

	get_telemetry = rospy.ServiceProxy('get_telemetry', srv.GetTelemetry)
	navigate = rospy.ServiceProxy('navigate', srv.Navigate)
	navigate_global = rospy.ServiceProxy('navigate_global', srv.NavigateGlobal)
	set_position = rospy.ServiceProxy('set_position', srv.SetPosition)
	set_velocity = rospy.ServiceProxy('set_velocity', srv.SetVelocity)
	set_attitude = rospy.ServiceProxy('set_attitude', srv.SetAttitude)
	set_rates = rospy.ServiceProxy('set_rates', srv.SetRates)
	land = rospy.ServiceProxy('land', Trigger)
	

	set_effect = rospy.ServiceProxy('led/set_effect', SetLEDEffect)
	

	hsv_min = np.array((100, 100, 100), np.uint8)
	hsv_max = np.array((180, 255, 200), np.uint8)
	

	def image_callback2(data):    #функция для выделения контуров и цетра фигуры
	    global cv_image
	    cv_image = bridge.imgmsg_to_cv2(data, 'bgr8')
	

	    hsv = cv.cvtColor(cv_image, cv.COLOR_BGR2HSV)
	    thresh = cv.inRange(hsv, hsv_min, hsv_max ) 
	    contours, hierarchy = cv.findContours(thresh.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_NONE)
	    contours = list(filter(lambda x: cv.contourArea(x) > 1, contours))
	    black_white = cv.bitwise_and(cv_image, cv_image, mask=thresh)
	    if len(contours) != 0:
	        cont = max(contours, key=cv.contourArea)
	

	        epsilon = 0.1*cv.arcLength(cont,True)
	        approx = cv.approxPolyDP(cont,epsilon,True)
	

	        cv.drawContours(cv_image, cont, -1, (255,0,0), 3, cv.LINE_AA)
	        moments = cv.moments(cont, 1)
	        dM01 = moments['m01']
	        dM10 = moments['m10']
	        dArea = moments['m00']
	        if dArea > 100:
	            x = int(dM10 / dArea)
	            y = int(dM01 / dArea)
	            cv.circle(cv_image, (x, y), 10, (0,255,254), -1)
	            cv.putText(cv_image, (str(x)), (x, y), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 200), 2)
	            cv.putText(cv_image, (str(y)), (x, y-30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 200), 2)
	

	    image_pub.publish(bridge.cv2_to_imgmsg(cv_image, 'bgr8'))
	

	

	def image_callback(data):    #функция для унавания распознаваемых он с помощью hsv
	    global cv_image
	    cv_image = bridge.imgmsg_to_cv2(data, 'bgr8')
	    hsv = cv.cvtColor(cv_image, cv.COLOR_BGR2HSV)
	    thresh = cv.inRange(hsv, hsv_min, hsv_max ) 
	    contours, hierarchy = cv.findContours(thresh.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
	    contours = list(filter(lambda x: cv.contourArea(x) > 1, contours))
	    black_white = cv.bitwise_and(cv_image, cv_image, mask=thresh)
	    if len(contours) != 0:
	        cont = max(contours, key=cv.contourArea)
	        cv.drawContours(cv_image, cont, -1, (255,0,0), 3, cv.LINE_AA)
	        moments = cv.moments(cont, 1)
	        dM01 = moments['m01']
	        dM10 = moments['m10']
	        dArea = moments['m00']
	        if dArea > 100:
	            x = int(dM10 / dArea)
	            y = int(dM01 / dArea)
	            cv.circle(cv_image, (x, y), 10, (0,255,254), -1)
	            cv.putText(cv_image, (str(x)), (x, y), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 200), 2)
	            cv.putText(cv_image, (str(y)), (x, y-30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 200), 2)
	

	    image_pub.publish(bridge.cv2_to_imgmsg(black_white, 'bgr8')) 
	

	

	def navigate_wait(x=0, y=0, z=1.5, yaw=0, speed=1, frame_id='aruco_map', auto_arm=False, tolerance=0.2):
	    navigate(x=x, y=y, z=z, yaw=yaw, speed=speed, frame_id=frame_id, auto_arm=auto_arm)
	

	    while not rospy.is_shutdown():
	        telem = get_telemetry(frame_id='navigate_target')
	        if math.sqrt(telem.x2 + telem.y2 + telem.z**2) < tolerance:
	            break
	        rospy.sleep(0.2)
	

	

	def square(side=2): (полёт по квадрату)
	    navigate_wait(side, 0, 0, frame_id='navigate_target')
	    telemetry = get_telemetry()
	    set_effect(r=255, g=0, b=0)
	    print(telemetry.x, telemetry.y, telemetry.z)
	    navigate_wait(0, side, 0, frame_id='navigate_target')
	    set_effect(r=0, g=255, b=0)
	    telemetry = get_telemetry()
	    print(telemetry.x, telemetry.y, telemetry.z)
	    navigate_wait(-side, 0, 0, frame_id='navigate_target')
	    set_effect(r=0, g=0, b=255)
	    telemetry = get_telemetry()
	    print(telemetry.x, telemetry.y, telemetry.z)
	   navigate_wait(0, -side, 0, frame_id='navigate_target')
	   set_effect(r=100, g=100, b=0)
	

	

	rospy.Subscriber('main_camera/image_raw', Image, image_callback2, queue_size=1)
	image_pub = rospy.Publisher('~debug', Image, queue_size = 1)
	rospy.spin()



